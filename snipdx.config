/*
 * Copyright (c) 2022, Repare.
 * Configure this as needed
 */
 
manifest {
  description     = 'SNiPDX pipeline'
  version         = "2.5.0"
  name            = "nf-snipdx"
  author          = 'Bruce Wollison'
  nextflowVersion = '>=20.07.0'
}

// set default max for CPUs/memory.
// these are meant to be overridden later, just here so
// the check_max() function doesn't complain if no smaller
// values are entered

params.max_cpus   = 256
params.max_memory = 2000.GB

/*
 * define containers for running jobs
 */

docker.enabled = true

process {
    withName:run_facet_script {
        container = 'snipdx_tools:prod_2.2'
    }
    withName:run_facet_script_with_purecn_diplogr {
        container = 'snipdx_tools:prod_2.2'
    }
    withName:snp_pileup {
        container = 'snipdx_tools:prod_2.2'
    }
    withName:batch_run_info {
        container = 'ubuntu:18.04'
    }
    withName:freebayes {
        container = 'freebayes:prod_1.0'
    }
    withName:dbsnp_annotate_variants {
        container = 'snpeff:1.0'
    }
    withName:purecn_coverage {
        container = 'markusriester/purecn:2.0.2'
    }
    withName:purecn {
        container = 'markusriester/purecn:2.0.2'
    }
    withName:callstate {
        container = 'quay.io/biocontainers/callstate:0.0.2--hbeb723e_0'
    }
    withName:purecn_biomarkers {
        container = 'markusriester/purecn:2.0.2'
    }
    withName:insert_metrics {
        // if this container creates errors, switch to the following one instead:
        //quay.io/biocontainers/samtools:1.15.1--h1170115_0
        container = "biocontainers/samtools:v1.9-4-deb_cv1"
    }
    withName:local_insert_metrics {
        container = "snipdx_tools:prod_2.2"
    }
    withName:rmarkdown_report_process {
        container = "rmarkdown:prod_1.0"
    }
    withName:get_chrom_plots_and_segments{
        container = 'snipdx_tools:prod_2.3'
    }
    withName:get_chrom_plots_and_segments_w_purecn_diplogr{
        container = 'snipdx_tools:prod_2.3'
    }
    withName:diplogr_calculation {
        container = 'python_tools:1.0'
    }
}


/*
 * machine requirements (general)
 */

process {
    withLabel: teeny_task{
        cpus   = { check_max(2, 'cpus') }
        memory = { check_max(4.GB, 'memory') }
    }
    withLabel: small_task{
        cpus   = { check_max(4, 'cpus') }
        memory = { check_max(16.GB, 'memory') }
    }
    withLabel: reg_task{
        cpus   = { check_max(8, 'cpus') }
        memory = { check_max(32.GB, 'memory') }
    }
    withLabel: large_task{
        cpus   = { check_max(16, 'cpus') }
        memory = { check_max(64.GB, 'memory') }
    }
}

/* 
 * defines execution profiles for different environments  
 */ 

profiles {

  // configuration for running on google life sciences for project repare-database
  gcp {
       process.executor = 'google-lifesciences'
       workDir          = 'gs://repare-nextflow-work/work_dir'
       google.location  = 'us-central1'
       google.region    = 'us-central1'
       google.project   = 'repare-database'

       includeConfig 'conf/gcp_process.config'
  }

  // configuration for running on google life sciences in repare-clinical
  gcpClin {
       process.executor = 'google-lifesciences'
       workDir          = 'gs://clinical-nextflow-work/work_dir'
       google.location  = 'us-central1'
       google.region    = 'us-central1'
       google.project   = 'repare-clinical'

       includeConfig 'conf/gcp_process.config'
  }

  // path to local reference files
  ref {
        params.vcf_fp              = "${projectDir}/refs/gnomad2.genomes.and.exomes.400bp.dedup.vcf.gz"
        params.panel_ga            = "${projectDir}/refs/panel_genes_annotated-v2.tsv"
        params.pon_fp_012222       = "${projectDir}/refs/pon.012222.with.is.RData"
        params.pon_fp_092722       = "${projectDir}/refs/pon.092722.RData"
        params.clust_info          = "${projectDir}/refs/is.clustering.110621.RData"
        params.pon_target_location = "${projectDir}/refs/pon.012222.targets.csv"
        params.snipdx_gene_coords  = "${projectDir}/refs/snipdx_gene_coords.txt"
  }

  // ref paths for purecn in gcp
  gcpRef {
        params.ref_genome                 = "gs://repare-reference-data/dnaseq/hg19/human/hg19.fa"
        params.ref_genome_index           = "gs://repare-reference-data/dnaseq/hg19/human/hg19.fa.fai"
        params.purecn_normal_db           = "gs://repare-reference-data/purecn/for_snipdx/normalDB_hg19.rds"
        params.purecn_mapping_bias_file   = "gs://repare-reference-data/purecn/for_snipdx/mapping_bias_hg19.rds"
        params.purecn_interval_file       = "gs://repare-reference-data/purecn/for_snipdx/targets_hg19_intervals_w_offtarget_resized_annotated.txt"
        params.purecn_interval_bed        = "gs://repare-reference-data/purecn/for_snipdx/targets_hg19_w_offtarget_resized.bed"
        params.dbsnp                      = "gs://repare-reference-data/purecn/dbsnp/00-All.vcf.gz"
        params.dbsnp_index                = "gs://repare-reference-data/purecn/dbsnp/00-All.vcf.gz.tbi"
  }

  // profile for running things locally. Set to your machines memory/cpu availability
  local {
        params.max_cpus                 = 4
        params.max_memory               = 6.GB
        google.location                 = 'us-central1'
        google.region                   = 'us-central1'
        google.project                  = 'repare-database'
  }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
// note: lovingly taken from nf-core RNAseq pipeline config
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}